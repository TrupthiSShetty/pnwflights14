{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Score\n",
      "0  I have bought several of the Vitality canned d...      5\n",
      "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
      "2  This is a confection that has been around a fe...      4\n",
      "3  If you are looking for the secret ingredient i...      2\n",
      "4  Great taffy at a great price.  There was a wid...      5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def read_text_file(f):\n",
    "    df_complete = pd.read_csv(f)\n",
    "    df = df_complete.loc[:,[\"Text\",\"Score\"]]\n",
    "    df.dropna(how=\"any\", inplace=True)    \n",
    "    return df\n",
    "\n",
    "df = read_text_file(r\"C:\\Users\\HPPC\\Reviews.csv\")\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score                                               Text\n",
      "0     5  ...at least I hope it remains available. It is...\n",
      "1     5  My grandson is a beef jerky addict. We don't h...\n",
      "2     5  This coffee has a really great taste asnd if v...\n",
      "3     5  Healthy edibles are a great treat for our 5 ye...\n",
      "4     5  I have never been one to buy chicken in a can ...\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "def sampling_dataset(df):\n",
    "    count = 5000\n",
    "    class_df_sampled = pd.DataFrame(columns = [\"Score\",\"Text\"])\n",
    "    temp = []\n",
    "    for c in df.Score.unique():\n",
    "        class_indexes = df[df.Score == c].index\n",
    "        random_indexes = np.random.choice(class_indexes, count, replace=False)\n",
    "        temp.append(df.loc[random_indexes])\n",
    "        \n",
    "    for each_df in temp:\n",
    "        class_df_sampled = pd.concat([class_df_sampled,each_df],axis=0)\n",
    "    \n",
    "    return class_df_sampled\n",
    "\n",
    "df = sampling_dataset(df)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "print (df.head())\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "w = re.compile(\"\\w+\",re.I)\n",
    "\n",
    "def label_sentences(df):\n",
    "    labeled_sentences = []\n",
    "    for index, datapoint in df.iterrows():\n",
    "        tokenized_words = re.findall(w,datapoint[\"Text\"].lower())\n",
    "        labeled_sentences.append(LabeledSentence(words=tokenized_words, tags=['SENT_%s' %index]))\n",
    "    return labeled_sentences\n",
    "\n",
    "def train_doc2vec_model(labeled_sentences):\n",
    "    model = Doc2Vec(alpha=0.025, min_alpha=0.025)\n",
    "    model.build_vocab(labeled_sentences)\n",
    "    for epoch in range(10):\n",
    "        model.train(labeled_sentences,total_examples =model.corpus_count,epochs=model.epochs)\n",
    "        model.alpha -= 0.002 \n",
    "        model.min_alpha = model.alpha\n",
    "        \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sen = label_sentences(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train_doc2vec_model(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score                                               Text  \\\n",
      "0     5  ...at least I hope it remains available. It is...   \n",
      "1     5  My grandson is a beef jerky addict. We don't h...   \n",
      "\n",
      "                                 vectorized_comments  \n",
      "0  [-0.2687241, 0.39540887, -1.1514533, 1.1078795...  \n",
      "1  [-0.52334917, 0.07890725, -0.48016855, 1.73405...  \n"
     ]
    }
   ],
   "source": [
    "def vectorize_comments(df,d2v_model):\n",
    "    y = []\n",
    "    comments = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        label = 'SENT_%s' %i\n",
    "        comments.append(d2v_model.docvecs[label])\n",
    "    df['vectorized_comments'] = comments\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = vectorize_comments(df,model)\n",
    "print (df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['Score'].astype('int')\n",
    "df['Score'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  5.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36248979591836733 ----------------Best Accuracy score on Cross Validation Sets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "def train_classifier(X,y):\n",
    "    n_estimators = [200,400]\n",
    "    min_samples_split = [2]\n",
    "    min_samples_leaf = [1]\n",
    "    bootstrap = [True]\n",
    "\n",
    "    parameters = {'n_estimators': n_estimators, 'min_samples_leaf': min_samples_leaf,\n",
    "                  'min_samples_split': min_samples_split}\n",
    "\n",
    "    clf = GridSearchCV(RFC(verbose=1,n_jobs=4), cv=4, param_grid=parameters)\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"vectorized_comments\"].T.tolist(), df[\"Score\"].T.tolist(), test_size=0.02, random_state=17)\n",
    "classifier = train_classifier(X_train,y_train)\n",
    "print (classifier.best_score_, \"----------------Best Accuracy score on Cross Validation Sets\")\n",
    "print (classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
